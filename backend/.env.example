# ============================================
# LLM Backend Configuration
# ============================================
# Seçenekler: 'ollama' veya 'gemini'
# Varsayılan: 'ollama'
LLM_BACKEND=ollama

# ============================================
# Ollama Configuration (LLM_BACKEND=ollama olduğunda)
# ============================================
# Ollama servisinin çalıştığı URL
# Varsayılan: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Kullanılacak Ollama modeli
# Popüler modeller: llama3.1:8b, llama3.1:70b, mistral:7b, qwen2.5:7b
# Modeli indirmek için: ollama pull llama3.1:8b
OLLAMA_MODEL=llama3.1:8b

# Embedding modeli (vektör arama için)
# Varsayılan: nomic-embed-text
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ============================================
# Google Gemini Configuration (LLM_BACKEND=gemini olduğunda)
# ============================================
# Google AI Studio'dan API anahtarı alın: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# ============================================
# Memory Backend Configuration
# ============================================
# Seçenekler: 'redis' veya 'in-memory'
# Varsayılan: 'redis' (production için önerilir)
MEMORY_BACKEND=redis

# Redis Configuration (MEMORY_BACKEND=redis olduğunda)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# ============================================
# Notlar:
# ============================================
# 1. Bu dosyayı .env olarak kopyalayın: cp .env.example .env
# 2. .env dosyasını düzenleyip kendi API anahtarlarınızı ekleyin
# 3. .env dosyası git'e commit edilmez (.gitignore'da)
