# SQL Veri Analisti - Text-to-SQL AI AsistanÄ±

Modern, kullanÄ±cÄ± dostu bir SQL veri analisti asistanÄ±. DoÄŸal dil ile veritabanÄ± sorgularÄ± oluÅŸturun ve sonuÃ§larÄ± gÃ¶rselleÅŸtirin.

## ğŸ¯ Ã–zellikler

- **DoÄŸal Dil SorgularÄ±**: TÃ¼rkÃ§e sorularÄ±nÄ±zÄ± SQL sorgularÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
- **GÃ¶rselleÅŸtirme**: Sorgu sonuÃ§larÄ±nÄ± grafiklerle gÃ¶rselleÅŸtirin
- **Veri YÃ¼kleme**: Kendi CSV/Excel dosyalarÄ±nÄ±zÄ± yÃ¼kleyin
- **GÃ¼venli SQL**: Sadece SELECT sorgularÄ±na izin verilir
- **ChatGPT TarzÄ± ArayÃ¼z**: Modern, sade ve kullanÄ±cÄ± odaklÄ± tasarÄ±m

## ğŸ“¸ Ekran GÃ¶rÃ¼ntÃ¼leri

### Ana Ekran
![Ana Ekran](screenshots/main-screen.png)

### Sorgu SonuÃ§larÄ±
![Sorgu SonuÃ§larÄ±](screenshots/query-results.png)

### Grafik GÃ¶rselleÅŸtirme
![Grafik GÃ¶rselleÅŸtirme](screenshots/chart-visualization.png)

### Veri YÃ¼kleme
![Veri YÃ¼kleme](screenshots/file-upload.png)

## ğŸš€ Kurulum

### 1. Backend Kurulumu

```bash
cd backend
pip install -r requirements.txt
```

### 2. LLM Model YapÄ±landÄ±rmasÄ±

Uygulama iki farklÄ± LLM backend'i destekler: **Ollama** (yerel, Ã¼cretsiz) ve **Google Gemini** (bulut, API anahtarÄ± gerekir).

#### Ollama KullanÄ±mÄ± (Ã–nerilen - Yerel ve Ãœcretsiz)

1. **Ollama'yÄ± yÃ¼kleyin:**
   ```bash
   # Linux/Mac
   curl -fsSL https://ollama.com/install.sh | sh
   
   # veya https://ollama.com/download adresinden indirin
   ```

2. **Ollama servisini baÅŸlatÄ±n:**
   ```bash
   ollama serve
   ```

3. **Ä°stediÄŸiniz modeli indirin:**
   ```bash
   # PopÃ¼ler modeller:
   ollama pull llama3.1:8b        # HÄ±zlÄ± ve hafif (Ã¶nerilen)
   ollama pull llama3.1:70b       # Daha gÃ¼Ã§lÃ¼ ama yavaÅŸ
   ollama pull mistral:7b         # Alternatif
   ollama pull qwen2.5:7b         # Alternatif
   ```

4. **`.env` dosyasÄ±nÄ± yapÄ±landÄ±rÄ±n:**
   ```bash
   cd backend
   cp .env.example .env
   ```
   
   `.env` dosyasÄ±nda:
   ```env
   LLM_BACKEND=ollama
   OLLAMA_BASE_URL=http://localhost:11434
   OLLAMA_MODEL=llama3.1:8b
   OLLAMA_EMBEDDING_MODEL=nomic-embed-text
   ```

#### Google Gemini KullanÄ±mÄ±

1. **Google AI Studio'dan API anahtarÄ± alÄ±n:**
   - https://aistudio.google.com/app/apikey adresine gidin
   - Google hesabÄ±nÄ±zla giriÅŸ yapÄ±n
   - "Create API Key" butonuna tÄ±klayÄ±n
   - API anahtarÄ±nÄ±zÄ± kopyalayÄ±n

2. **`.env` dosyasÄ±nÄ± yapÄ±landÄ±rÄ±n:**
   ```bash
   cd backend
   cp .env.example .env
   ```
   
   `.env` dosyasÄ±nda:
   ```env
   LLM_BACKEND=gemini
   GOOGLE_API_KEY=your-google-api-key-here
   ```

### 3. Memory Backend YapÄ±landÄ±rmasÄ±

**Redis KullanÄ±mÄ± (Ã–nerilen):**
```bash
# Docker ile Redis baÅŸlatma
docker run -d -p 6379:6379 redis:alpine

# veya sistem Redis servisi
sudo systemctl start redis
```

`.env` dosyasÄ±nda:
```env
MEMORY_BACKEND=redis
REDIS_HOST=localhost
REDIS_PORT=6379
```

**In-Memory KullanÄ±mÄ± (GeliÅŸtirme iÃ§in):**
```env
MEMORY_BACKEND=in-memory
```

### 4. Backend'i BaÅŸlatÄ±n

```bash
cd backend
uvicorn app.main:app --reload
```

Backend `http://localhost:8000` adresinde Ã§alÄ±ÅŸacak.

### 5. Frontend Kurulumu

```bash
cd frontend
npm install
npm run dev
```

Frontend `http://localhost:3000` adresinde Ã§alÄ±ÅŸacak.

## ğŸ“– KullanÄ±m

1. Backend ve frontend'i baÅŸlatÄ±n (yukarÄ±daki kurulum adÄ±mlarÄ±nÄ± takip edin)
2. Ä°steÄŸe baÄŸlÄ± olarak kendi CSV/Excel veritabanÄ±nÄ±zÄ± yÃ¼kleyin
3. DoÄŸal dilde sorularÄ±nÄ±zÄ± sorun (Ã¶rn: "En Ã§ok satan 5 albÃ¼m hangisi?")
4. AI SQL sorgusu Ã¶nerecek, onayladÄ±ktan sonra sonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin
5. SonuÃ§larÄ± CSV/Excel/JSON olarak indirin

## âš™ï¸ YapÄ±landÄ±rma DetaylarÄ±

### Model SeÃ§imi: Ollama vs Gemini

#### Ollama (Ã–nerilen - Yerel ve Ãœcretsiz)
- âœ… **Avantajlar:**
  - Tamamen Ã¼cretsiz
  - Verileriniz yerelde kalÄ±r (gizlilik)
  - Ä°nternet baÄŸlantÄ±sÄ± gerektirmez
  - SÄ±nÄ±rsÄ±z kullanÄ±m
  
- âš ï¸ **Dezavantajlar:**
  - Yerel kaynak kullanÄ±mÄ± (RAM/CPU)
  - Model indirme gerekir
  - Genellikle Gemini'den daha yavaÅŸ

**Kurulum:**
```bash
# 1. Ollama'yÄ± yÃ¼kleyin
curl -fsSL https://ollama.com/install.sh | sh

# 2. Servisi baÅŸlatÄ±n
ollama serve

# 3. Model indirin
ollama pull llama3.1:8b

# 4. .env dosyasÄ±nÄ± yapÄ±landÄ±rÄ±n
LLM_BACKEND=ollama
OLLAMA_MODEL=llama3.1:8b
```

#### Google Gemini (Bulut TabanlÄ±)
- âœ… **Avantajlar:**
  - Ã‡ok hÄ±zlÄ± yanÄ±t sÃ¼releri
  - GÃ¼Ã§lÃ¼ model performansÄ±
  - Yerel kaynak kullanmaz
  
- âš ï¸ **Dezavantajlar:**
  - API anahtarÄ± gerekir
  - Ãœcretli (Ã¼cretsiz kotasÄ± var)
  - Veriler Google'a gÃ¶nderilir
  - Ä°nternet baÄŸlantÄ±sÄ± gerekir

**Kurulum:**
```bash
# 1. API anahtarÄ± alÄ±n: https://aistudio.google.com/app/apikey
# 2. .env dosyasÄ±nÄ± yapÄ±landÄ±rÄ±n
LLM_BACKEND=gemini
GOOGLE_API_KEY=your-api-key-here
```

### Hangi Modeli SeÃ§meliyim?

- **GeliÅŸtirme/Test iÃ§in:** Ollama (`llama3.1:8b`) - Ãœcretsiz ve hÄ±zlÄ± kurulum
- **Production iÃ§in:** 
  - KÃ¼Ã§Ã¼k Ã¶lÃ§ek: Ollama (`llama3.1:8b` veya `llama3.1:70b`)
  - BÃ¼yÃ¼k Ã¶lÃ§ek: Google Gemini (daha hÄ±zlÄ± ve gÃ¼venilir)
- **Gizlilik Ã¶nemliyse:** Ollama (veriler yerelde kalÄ±r)

## ğŸ¤– Desteklenen LLM Modelleri

### Ollama (Yerel, Ãœcretsiz)
- âœ… **llama3.1:8b** - HÄ±zlÄ± ve hafif (Ã¶nerilen)
- âœ… **llama3.1:70b** - Daha gÃ¼Ã§lÃ¼ ama yavaÅŸ
- âœ… **mistral:7b** - Alternatif seÃ§enek
- âœ… **qwen2.5:7b** - Alternatif seÃ§enek
- âœ… DiÄŸer Ollama modelleri

### Google Gemini (Bulut, API anahtarÄ± gerekir)
- âœ… **gemini-2.0-flash-exp** - HÄ±zlÄ± ve gÃ¼Ã§lÃ¼
- âœ… **gemini-2.5-flash** - GÃ¼ncel model

### Model DeÄŸiÅŸtirme

Model deÄŸiÅŸtirmek iÃ§in `backend/.env` dosyasÄ±nÄ± dÃ¼zenleyin:

```env
# Ollama iÃ§in
LLM_BACKEND=ollama
OLLAMA_MODEL=mistral:7b  # Ä°stediÄŸiniz modeli yazÄ±n

# Gemini iÃ§in
LLM_BACKEND=gemini
GOOGLE_API_KEY=your-api-key
```

DeÄŸiÅŸikliklerin uygulanmasÄ± iÃ§in backend'i yeniden baÅŸlatÄ±n.

## ğŸ› ï¸ Teknolojiler

- **Backend**: FastAPI, LangChain, SQLite
- **Frontend**: Next.js, React, TypeScript, Tailwind CSS
- **AI**: Ollama (yerel) veya Google Gemini (bulut)
- **Memory**: Redis veya In-Memory
- **Vector Store**: ChromaDB

## ğŸ“ Lisans

MIT
